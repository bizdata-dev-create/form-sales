{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RnUTOYIaFBb"
   },
   "source": [
    "# äº‹å‰è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptwJFOn7p4DD",
    "outputId": "47bde079-b9f8-48eb-c130-0a0339c0aa49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\qingy\\anaconda3\\lib\\site-packages (2.179.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.40.3)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.25.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (6.32.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!pip install google-api-python-client beautifulsoup4\n",
    "!pip -q install openpyxl odfpy\n",
    "!pip -q install gspread gspread_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4y2w5yroWJuW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCLOUD_PROJECT_ID: test-250817-469308\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from google.cloud import bigquery\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã® .env ã‚’ç‰¹å®šã—ã¦ä¸Šæ›¸ãèª­ã¿è¾¼ã¿\n",
    "project_root = next(p for p in [Path.cwd(), *Path.cwd().parents] if (p / \".env\").exists())\n",
    "env_file = str(project_root / \".env\")\n",
    "load_dotenv(dotenv_path=env_file, override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "CSE_ID = os.getenv(\"CSE_ID\", \"\")\n",
    "GCLOUD_PROJECT_ID = os.getenv(\"GClOUD_PROJECT_ID\", \"\")\n",
    "print(\"GCLOUD_PROJECT_ID:\",GCLOUD_PROJECT_ID)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qingy\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å•ã„åˆã‚ã›URLå–å¾—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å•ã„åˆã‚ã›å–å¾—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "j9Q1McZspUh7"
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from googleapiclient.discovery import build\n",
    "from typing import Optional, Tuple, List\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# â”€â”€â”€ ãƒ­ã‚®ãƒ³ã‚°è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# â”€â”€â”€ Google Custom Search API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_search_client(api_key: str, cse_id: str):\n",
    "    logging.debug(\"Creating Custom Search client\")\n",
    "    client = build(\"customsearch\", \"v1\", developerKey=api_key).cse()\n",
    "    logging.debug(\"Custom Search client created\")\n",
    "    return client\n",
    "\n",
    "# â”€â”€â”€ ä¼šç¤¾åã§å…¬å¼ã‚µã‚¤ãƒˆ URL ã‚’å–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_hp_url(company_name: str, cse_client, cse_id: str) -> str:\n",
    "    logging.debug(f\"Searching HP URL for: {company_name}\")\n",
    "    try:\n",
    "        res = cse_client.list(q=company_name, cx=cse_id, num=1).execute()\n",
    "        items = res.get(\"items\", [])\n",
    "        hp = items[0][\"link\"] if items else None\n",
    "        logging.debug(f\"â†’ HP URL found: {hp}\")\n",
    "        return hp\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching HP URL for {company_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# â”€â”€â”€ ãƒšãƒ¼ã‚¸ãŒãƒ•ã‚©ãƒ¼ãƒ ã‹åˆ¤å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def is_form_page(soup: BeautifulSoup) -> bool:\n",
    "\n",
    "    text_types ={\"text\",\"email\",\"tel\",\"number\"}\n",
    "    inputs = soup.find_all(\n",
    "        \"input\",\n",
    "        attrs={\n",
    "            \"type\": lambda t: t and t.lower() in text_types,\n",
    "            \"name\": True\n",
    "        }\n",
    "    )\n",
    "    return len(inputs) >= 3\n",
    "\n",
    "    return True\n",
    "\n",
    "# â”€â”€â”€ å•ã„åˆã›URLå–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_contact_url(hp_url: str, timeout: float = 5.0) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    hp_url ã‹ã‚‰æœ€å¤§æ·±åº¦3ã¾ã§ãƒªãƒ³ã‚¯ã‚’ãŸã©ã‚Šã€\n",
    "    ãŠå•ã„åˆã‚ã›ãƒ•ã‚©ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã¨åˆ¤æ–­ã§ããŸ URL ã‚’è¿”ã™ã€‚\n",
    "    è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° Noneã€‚\n",
    "    \"\"\"\n",
    "    logging.debug(f\"Searching contact URL on: {hp_url}\")\n",
    "    if not hp_url:\n",
    "        logging.warning(\"No HP URL provided, skipping contact search\")\n",
    "        return None\n",
    "\n",
    "    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©\n",
    "    primary_kw   : List[str] = [\"å•ã„åˆã‚ã›\", \"ãŠå•ã„åˆã‚ã›\", \"å•åˆã‚ã›\", \"å•ã„åˆã›\", \"ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ\", \"contact\", \"inquiry\", \"request\", \"entry\"]\n",
    "    secondary_kw : List[str] = [\"ãƒ•ã‚©ãƒ¼ãƒ \", \"ãã®ä»–\", \"æ¡ç”¨\", \"IR\", \"æœ¬éƒ¨\"] + primary_kw\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    def fetch_soup(url: str) -> Tuple[Optional[BeautifulSoup], Optional[str]]:\n",
    "        \"\"\" URL ã‚’ GET ã—ã¦ (soup, æœ€çµ‚çš„ãªçµ¶å¯¾URL) ã‚’è¿”ã™ \"\"\"\n",
    "        try:\n",
    "            resp = session.get(url, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            return BeautifulSoup(resp.text, \"html.parser\"), resp.url\n",
    "        except Exception as e:\n",
    "            # logging.warning(f\"  â†’ Failed to fetch {url}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def extract_links(soup: BeautifulSoup, base_url: str, kws: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        <a href> ã® text or href ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã‚‚ã®ã‚’æŠ½å‡ºã—ã€\n",
    "        çµ¶å¯¾URLã§è¿”ã™\n",
    "        \"\"\"\n",
    "        results: List[str] = []\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            text = a.get_text(strip=True).lower()\n",
    "            href = a[\"href\"].lower()\n",
    "            if any(kw in text for kw in kws) or any(kw in href for kw in kws):\n",
    "                abs_url = urljoin(base_url, a[\"href\"])\n",
    "                logging.debug(f\"   â†’ Candidate link: {abs_url}\")\n",
    "                results.append(abs_url)\n",
    "        return results\n",
    "\n",
    "    # æ·±åº¦ã”ã¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ—\n",
    "    kw_by_depth = {1: primary_kw, 2: secondary_kw, 3: secondary_kw}\n",
    "\n",
    "    # BFS ã§æœ€å¤§æ·±åº¦3ã¾ã§æ¢ç´¢\n",
    "    frontier = [(hp_url, 0)]  # (URL, depth)\n",
    "    visited  = set()\n",
    "\n",
    "    while frontier:\n",
    "        url, depth = frontier.pop(0)\n",
    "        if url in visited or depth >= 3:\n",
    "            continue\n",
    "        visited.add(url)\n",
    "\n",
    "        soup, real_url = fetch_soup(url)\n",
    "        if soup is None:\n",
    "            continue\n",
    "\n",
    "        logging.debug(f\"[depth={depth}] Visiting: {real_url}\")\n",
    "\n",
    "        # depth>0 ã®ãƒšãƒ¼ã‚¸ã§ãƒ•ã‚©ãƒ¼ãƒ åˆ¤å®š\n",
    "        if depth > 0 and is_form_page(soup):\n",
    "            # logging.info(f\"Contact form URL found at depth {depth}: {real_url}\")\n",
    "            # print(f\"Contact form URL found at depth {depth}: {real_url}\")\n",
    "            return real_url\n",
    "\n",
    "        # æ¬¡ã®æ·±åº¦ã®ãƒªãƒ³ã‚¯ã‚’æŠ½å‡ºã—ã¦ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ \n",
    "        next_depth = depth + 1\n",
    "        kws = kw_by_depth.get(next_depth, [])\n",
    "        if not kws:\n",
    "            continue\n",
    "\n",
    "        for link in extract_links(soup, real_url, kws):\n",
    "            frontier.append((link, next_depth))\n",
    "\n",
    "    logging.info(\"Contact form URL not found within depth 3\")\n",
    "    return None\n",
    "\n",
    "def fill_contact_from_hp(df):\n",
    "    mask = df['contact_url'].isna() & df['hp_url'].str.contains(r'contact|inquiry|toiawase|ãŠå•ã„åˆã‚ã›|ãŠå•åˆã›', case=False, na=False)\n",
    "    df.loc[mask, 'contact_url'] = df.loc[mask, 'hp_url']\n",
    "    return df\n",
    "\n",
    "\n",
    "# â”€â”€â”€ DataFrame ã«å¯¾ã—ã¦ä¸€æ‹¬å‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def fill_urls(df: pd.DataFrame, api_key: str, cse_id: str) -> pd.DataFrame:\n",
    "    cse = make_search_client(api_key, cse_id)\n",
    "    hp_urls = []\n",
    "    contact_urls = []\n",
    "\n",
    "    for i, name in tqdm(enumerate(df[\"company_name\"], start=1)):\n",
    "        # print(f\"=== å‡¦ç†é–‹å§‹ {i}/{len(df)}: {name} ===\")\n",
    "        # logging.info(f\"=== å‡¦ç†é–‹å§‹ {i}/{len(df)}: {name} ===\")\n",
    "\n",
    "        # å…¬å¼ã‚µã‚¤ãƒˆ URL\n",
    "        hp = get_hp_url(name, cse, cse_id)\n",
    "        hp_urls.append(hp)\n",
    "\n",
    "        # å•ã„åˆã‚ã›ãƒ•ã‚©ãƒ¼ãƒ  URL\n",
    "        contact = get_contact_url(hp)\n",
    "        contact_urls.append(contact)\n",
    "\n",
    "        logging.info(f\"â†’ çµæœ: HP={hp}, Contact={contact}\\n\")\n",
    "\n",
    "        time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–\n",
    "\n",
    "    df[\"hp_url\"] = hp_urls\n",
    "    df[\"contact_url\"] = contact_urls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 21:39:27,572 DEBUG Creating Custom Search client\n",
      "2025-09-01 21:39:27,586 INFO file_cache is only supported with oauth2client<4.0.0\n",
      "2025-09-01 21:39:27,595 DEBUG Custom Search client created\n",
      "2025-09-01 21:39:27,602 DEBUG Creating Custom Search client\n",
      "2025-09-01 21:39:27,609 INFO file_cache is only supported with oauth2client<4.0.0\n",
      "2025-09-01 21:39:27,621 DEBUG Custom Search client created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_api_key: AIzaSyBfFN19zSBQqai6m3lbMkNDN2UZ8EpReU8\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã® .env ã‚’èª­ã¿è¾¼ã‚€\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "CSE_ID = os.getenv(\"CSE_ID\", \"\")\n",
    "cse = make_search_client(GOOGLE_API_KEY, CSE_ID)\n",
    "print(\"google_api_key:\",GOOGLE_API_KEY)\n",
    "cse = make_search_client(GOOGLE_API_KEY, CSE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAK_42aaWSrB"
   },
   "source": [
    "## ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆä¸Šä¸æ˜ã®ã‚‚ã®ã‚’ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ckdsDSCmjO8K"
   },
   "outputs": [],
   "source": [
    "# è¿½åŠ : ãƒãƒƒã‚·ãƒ¥ä»˜ãã‚¢ãƒ³ã‚«ãƒ¼ã‚‚å€™è£œã«å…¥ã‚Œã‚‹\n",
    "COMMON_RELATIVE_PATHS = [\n",
    "    \"/contact\",\n",
    "    \"/contact-us\",\n",
    "    \"/contacact.html\",\n",
    "    \"/contact/other/\",\n",
    "    \"/contact/others/\",\n",
    "    \"/contact/form\",\n",
    "    \"/contact/recruit/\",\n",
    "    \"/inquiry\",\n",
    "    \"/inquiries\",\n",
    "    \"/request\",\n",
    "    \"/requests\",\n",
    "    \"#contact\",            # â† ã“ã‚Œã‚’è¿½åŠ \n",
    "]\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fill_contact_url(df: pd.DataFrame, timeout: float = 7.0) -> pd.DataFrame:\n",
    "    null_mask = df[\"contact_url\"].isna() | df[\"contact_url\"].astype(str).str.strip().eq(\"\")\n",
    "    print(null_mask)\n",
    "    for idx, row in tqdm(df[null_mask].iterrows(), total=null_mask.sum()):\n",
    "        base_url = row.get(\"hp_url\")\n",
    "        if not base_url:\n",
    "            continue\n",
    "        # ãƒ™ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ã¯1å›ã ã‘å–å¾—ï¼ˆ#fragmentç”¨ï¼‰\n",
    "        soup_home = None\n",
    "        try:\n",
    "            res_home = requests.get(base_url, timeout=timeout)\n",
    "            if res_home.status_code == 200:\n",
    "                soup_home = BeautifulSoup(res_home.content, \"html.parser\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching base page {base_url}: {e}\")\n",
    "\n",
    "        tested = set()\n",
    "        found = False\n",
    "\n",
    "        for path in COMMON_RELATIVE_PATHS:\n",
    "            # ãƒãƒƒã‚·ãƒ¥ï¼ˆ#...ï¼‰ã¯ãƒšãƒ¼ã‚¸å†…ã‚¢ãƒ³ã‚«ãƒ¼æ‰±ã„\n",
    "            if path.startswith(\"#\"):\n",
    "                if soup_home is None:\n",
    "                    continue  # ãƒ›ãƒ¼ãƒ å–å¾—å¤±æ•—æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "                # è©²å½“ã‚¢ãƒ³ã‚«ãƒ¼ãŒå­˜åœ¨ã™ã‚‹ã‹\n",
    "                target = soup_home.select_one(path)  # ä¾‹: '#contact'\n",
    "                if not target:\n",
    "                    continue\n",
    "\n",
    "                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å˜ä½ã§ãƒ•ã‚©ãƒ¼ãƒ ã‚‰ã—ã•ã‚’åˆ¤å®šï¼ˆã ã‚ãªã‚‰ãƒšãƒ¼ã‚¸å…¨ä½“ã§åˆ¤å®šï¼‰\n",
    "                try:\n",
    "                    if is_form_page(target) or is_form_page(soup_home):\n",
    "                        contact_url = urljoin(base_url, path)\n",
    "                        df.at[idx, \"contact_url\"] = contact_url\n",
    "                        print(f\"Found contact URL (fragment): {contact_url}\")\n",
    "                        found = True\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    # is_form_page ãŒ Tag ã‚’æƒ³å®šã—ã¦ã„ãªã„å ´åˆã¯ãƒšãƒ¼ã‚¸å…¨ä½“ã§å†åˆ¤å®š\n",
    "                    try:\n",
    "                        if is_form_page(soup_home):\n",
    "                            contact_url = urljoin(base_url, path)\n",
    "                            df.at[idx, \"contact_url\"] = contact_url\n",
    "                            print(f\"Found contact URL (fragment-fallback): {contact_url}\")\n",
    "                            found = True\n",
    "                            break\n",
    "                    except Exception as ee:\n",
    "                        print(f\"is_form_page error on fragment {path}: {ee}\")\n",
    "                continue\n",
    "\n",
    "            # é€šå¸¸ã®ç›¸å¯¾ãƒ‘ã‚¹ã¯ä»Šã¾ã§é€šã‚Šå–å¾—ã—ã¦åˆ¤å®š\n",
    "            test_url = urljoin(base_url, path)\n",
    "            if test_url in tested:\n",
    "                continue\n",
    "            tested.add(test_url)\n",
    "\n",
    "            try:\n",
    "                res = requests.get(test_url, timeout=timeout)\n",
    "                if res.status_code == 200:\n",
    "                    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "                    if is_form_page(soup):\n",
    "                        df.at[idx, \"contact_url\"] = test_url\n",
    "                        print(f\"Found contact URL: {test_url}\")\n",
    "                        found = True\n",
    "                        break  # æœ€åˆã«è¦‹ã¤ã‘ãŸãƒ•ã‚©ãƒ¼ãƒ ã§çµ‚äº†\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {test_url}: {e}\")\n",
    "                continue  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚„æ¥ç¶šã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–\n",
    "\n",
    "        # è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ã€ãƒ›ãƒ¼ãƒ å†…ã®<a href=\"#...\">ã‹ã‚‰#contactç³»ã‚’è£œè¶³ï¼ˆä¿é™ºï¼‰\n",
    "        if not found and soup_home is not None:\n",
    "            try:\n",
    "                anchors = soup_home.select('a[href^=\"#\"]')\n",
    "                for a in anchors:\n",
    "                    href = a.get(\"href\", \"\")\n",
    "                    text = (a.get_text() or \"\") + \" \" + href\n",
    "                    if re.search(r\"(contact|inquiry|ãŠå•ã„åˆã‚ã›|ãŠå•åˆã›|å•åˆã›)\", text, re.I):\n",
    "                        target = soup_home.select_one(href)\n",
    "                        if target and (is_form_page(target) or is_form_page(soup_home)):\n",
    "                            contact_url = urljoin(base_url, href)\n",
    "                            df.at[idx, \"contact_url\"] = contact_url\n",
    "                            print(f\"Found contact URL (fragment-auto): {contact_url}\")\n",
    "                            break\n",
    "            except Exception as e:\n",
    "                print(f\"Error scanning fragments on {base_url}: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "n2bNifpYYm0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ”¹å–„ç‰ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé–¢æ•°å®šç¾©å®Œäº†ï¼ˆAPIåˆ¶é™å¯¾ç­–ä»˜ãï¼‰\n",
      "ä½¿ç”¨æ–¹æ³•: export_unknown_contacts_to_gsheet_improved(contact_url_filled_df, failure_storage_SPREADSHEET_ID, 'å•ã„åˆã‚ã›URLæœªå–å¾—')\n"
     ]
    }
   ],
   "source": [
    "# === æ”¹å–„ç‰ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé–¢æ•°ï¼ˆAPIåˆ¶é™å¯¾ç­–ä»˜ãï¼‰ ===\n",
    "def export_unknown_contacts_to_gsheet_improved(df, spreadsheet_id, sheet_name):\n",
    "    \"\"\"\n",
    "    æ”¹å–„ç‰ˆï¼šå•ã„åˆã‚ã›URLãŒæœªå–å¾—ã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’Google Sheetsã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹\n",
    "    ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¦æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã€APIåˆ¶é™å¯¾ç­–ä»˜ãï¼‰\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        from google.oauth2.service_account import Credentials\n",
    "        import os\n",
    "        import time\n",
    "        \n",
    "        # èªè¨¼æƒ…å ±ã®è¨­å®š\n",
    "        scope = [\n",
    "            'https://spreadsheets.google.com/feeds',\n",
    "            'https://www.googleapis.com/auth/drive',\n",
    "            'https://www.googleapis.com/auth/spreadsheets'\n",
    "        ]\n",
    "        \n",
    "        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèªï¼ˆVMå¯¾å¿œï¼‰\n",
    "        project_root = get_form_sales_root()\n",
    "        service_account_key_path = project_root / \"secrets\" / \"form-sales-log-bffd68dc6996.json\"\n",
    "        \n",
    "        if not service_account_key_path.exists():\n",
    "            print(f\"âŒ ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {service_account_key_path}\")\n",
    "            return export_unknown_contacts_to_csv(df)\n",
    "        \n",
    "        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨\n",
    "        credentials = Credentials.from_service_account_file(\n",
    "            str(service_account_key_path), \n",
    "            scopes=scope\n",
    "        )\n",
    "        gc = gspread.authorize(credentials)\n",
    "        \n",
    "        print(f\"âœ… èªè¨¼æˆåŠŸ: {credentials.service_account_email}\")\n",
    "        \n",
    "        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã\n",
    "        try:\n",
    "            spreadsheet = gc.open_by_key(spreadsheet_id)\n",
    "            print(f\"âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ: {spreadsheet.title}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            return export_unknown_contacts_to_csv(df)\n",
    "        \n",
    "        # ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã¾ãŸã¯ä½œæˆ\n",
    "        try:\n",
    "            worksheet = spreadsheet.worksheet(sheet_name)\n",
    "            print(f\"âœ… æ—¢å­˜ã‚·ãƒ¼ãƒˆã‚’ä½¿ç”¨: {sheet_name}\")\n",
    "        except gspread.WorksheetNotFound:\n",
    "            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=20)\n",
    "            print(f\"âœ… æ–°è¦ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ: {sheet_name}\")\n",
    "        \n",
    "        # å•ã„åˆã‚ã›URLãŒæœªå–å¾—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "        unknown_contacts = df[\n",
    "            df[\"contact_url\"].isna() | \n",
    "            (df[\"contact_url\"].str.strip() == \"\") |\n",
    "            (df[\"contact_url\"] == \"None\")\n",
    "        ].copy()\n",
    "        \n",
    "        if len(unknown_contacts) == 0:\n",
    "            print(\"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹æœªå–å¾—ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ“Š ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯¾è±¡: {len(unknown_contacts)}ä»¶\")\n",
    "        \n",
    "        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª\n",
    "        existing_data = worksheet.get_all_values()\n",
    "        print(f\"ğŸ“‹ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(existing_data)}\")\n",
    "        \n",
    "        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰\n",
    "        if len(existing_data) == 0:\n",
    "            # ã‚·ãƒ¼ãƒˆãŒç©ºã®å ´åˆã€ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ \n",
    "            print(\"ï¿½ï¿½ ç©ºã®ã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã™\")\n",
    "            set_with_dataframe(worksheet, unknown_contacts)\n",
    "        else:\n",
    "            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ãƒãƒƒãƒå‡¦ç†ã§ä¸€æ‹¬è¿½åŠ ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰\n",
    "            print(\"ï¿½ï¿½ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚è¡Œã‹ã‚‰æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬è¿½åŠ ã—ã¾ã™\")\n",
    "            \n",
    "            # æœ€çµ‚è¡Œã®è¡Œç•ªå·ã‚’å–å¾—\n",
    "            next_row = len(existing_data) + 1\n",
    "            \n",
    "            # ãƒãƒƒãƒå‡¦ç†ã§ä¸€æ‹¬è¿½åŠ ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰\n",
    "            batch_data = []\n",
    "            for row in unknown_contacts.values:\n",
    "                # ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—åˆ—ã¨ã—ã¦å¤‰æ›ï¼ˆNoneã‚’ç©ºæ–‡å­—åˆ—ã«ï¼‰\n",
    "                row_data = [str(val) if val is not None else \"\" for val in row]\n",
    "                batch_data.append(row_data)\n",
    "            \n",
    "            # ä¸€æ‹¬ã§ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ \n",
    "            worksheet.update(f'A{next_row}', batch_data)\n",
    "            \n",
    "            # APIåˆ¶é™å¯¾ç­–ã®ãŸã‚å°‘ã—å¾…æ©Ÿ\n",
    "            time.sleep(2)\n",
    "            \n",
    "            print(f\"âœ… {len(unknown_contacts)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’{next_row}è¡Œç›®ã‹ã‚‰ä¸€æ‹¬è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "        \n",
    "        print(f\"ğŸ‰ å®Œäº†: {len(unknown_contacts)}ä»¶ã®æœªå–å¾—ãƒ‡ãƒ¼ã‚¿ã‚’{sheet_name}ã‚·ãƒ¼ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Sheetsã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        print(\"CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™...\")\n",
    "        export_unknown_contacts_to_csv(df)\n",
    "\n",
    "def export_unknown_contacts_to_csv(df, filename=None):\n",
    "    \"\"\"\n",
    "    CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹é–¢æ•°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        from datetime import datetime\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"unknown_contacts_{timestamp}.csv\"\n",
    "    \n",
    "    # å•ã„åˆã‚ã›URLãŒæœªå–å¾—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "    unknown_contacts = df[\n",
    "        df[\"contact_url\"].isna() | \n",
    "        (df[\"contact_url\"].str.strip() == \"\") |\n",
    "        (df[\"contact_url\"] == \"None\")\n",
    "    ].copy()\n",
    "    \n",
    "    if len(unknown_contacts) == 0:\n",
    "        print(\"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹æœªå–å¾—ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“\")\n",
    "        return\n",
    "    \n",
    "    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "    unknown_contacts.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {filename}\")\n",
    "    print(f\"ï¿½ï¿½ ä¿å­˜ä»¶æ•°: {len(unknown_contacts)}ä»¶\")\n",
    "\n",
    "print(\"âœ… æ”¹å–„ç‰ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé–¢æ•°å®šç¾©å®Œäº†ï¼ˆAPIåˆ¶é™å¯¾ç­–ä»˜ãï¼‰\")\n",
    "print(\"ä½¿ç”¨æ–¹æ³•: export_unknown_contacts_to_gsheet_improved(contact_url_filled_df, failure_storage_SPREADSHEET_ID, 'å•ã„åˆã‚ã›URLæœªå–å¾—')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twlHm1UABx98"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jivy57lYhj0k"
   },
   "source": [
    "# å–¶æ¥­æ–‡ç« ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAuEPnLZFE-h"
   },
   "source": [
    "## æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dXNYHOYfekro"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ora6nrXgZ7fM"
   },
   "source": [
    "## ä¼šç¤¾ã®æƒ…å ±å–å¾—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RehXryURvVyo"
   },
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "def classify_business_details(api_key: str, hp_url: str,\n",
    "                              model: str=\"gemini-2.0-flash\",\n",
    "                              temperature: float=0.0,\n",
    "                              timeout: int=300) -> dict:\n",
    "    # â† ã“ã“ã§ timeout ã‚’ã¾ã¨ã‚ã¦åŠ¹ã‹ã›ã‚‹ï¼ˆrequest_options ã¯ä½¿ã‚ãªã„ï¼‰\n",
    "    client = genai.Client(api_key=api_key, http_options={'api_version': 'v1alpha'})\n",
    "\n",
    "    prompt = PROMPT_CLASSIFY.format(hp_url=hp_url,vocab_list=\", \".join(BUSINESS_TYPE_VOCAB))\n",
    "    # print(\"=\"*80)\n",
    "    # print(prompt)\n",
    "    # print(\"=\"*80)\n",
    "\n",
    "    system_instruction=(\n",
    "        \"å…¬å¼ã‚µã‚¤ãƒˆã®ä¸€æ¬¡æƒ…å ±ã®ã¿ã‚’æ ¹æ‹ ã«æŠ½å‡ºã—ã€\"\n",
    "        \"ä»¥ä¸‹ã‚­ãƒ¼ã ã‘ã®JSONæ–‡å­—åˆ—ã‚’è¿”ã™ã€‚ä½™è¨ˆãªæ–‡ã‚„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¯ä¸€åˆ‡ç¦æ­¢ï¼š\"\n",
    "        \"company_display_name, business_type, other_label, strengths, values, \"\n",
    "        \"address_text, evidence, confidence\"\n",
    "    ),\n",
    "\n",
    "    # ãƒ„ãƒ¼ãƒ«ä½µç”¨æ™‚ã¯ response_mime_type/response_schema ã¯ä»˜ã‘ãªã„ï¼ˆ400å›é¿ï¼‰\n",
    "\n",
    "    # æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’æœ‰åŠ¹åŒ–ï¼ˆã‚ãªãŸã®ä¾‹ã¨åŒã˜æ›¸å¼ï¼‰\n",
    "    config = gtypes.GenerateContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        tools=[{\"google_search\": {}}],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    # å®Ÿè¡Œ\n",
    "    resp = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_instruction,\n",
    "            tools=[{\"google_search\": {}}],\n",
    "            temperature=temperature,\n",
    "        ),\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    raw = (resp.text or \"\").strip()\n",
    "    raw = re.sub(r\"^```json\\s*|\\s*```$\", \"\", raw).strip()\n",
    "    return raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf0DdHRe920T"
   },
   "source": [
    "#### ãƒŸãƒ‹ãƒ†ã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "2ZAAuEpGqG-t",
    "outputId": "0a68d9cc-cf31-47b4-fc43-68806e823007"
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    # \"https://www.2and4-auto.jp/\",\n",
    "    # \"https://www.cardrshuu.com/#contact\",\n",
    "    # \"http://www.nomiyama-car.com/contact/\",\n",
    "    # \"https://h-bpc.com/\",\n",
    "    # \"https://tauros-japan.com/\",\n",
    "    # \"https://www.saitomotor-hirosaki.com/\",\n",
    "    # \"https://kurumayakoubou.jp/\",\n",
    "]\n",
    "for url in urls:\n",
    "  prompt = PROMPT_CLASSIFY.format(hp_url=url,vocab_list=\", \".join(BUSINESS_TYPE_VOCAB))\n",
    "  for i in range(1):\n",
    "    resp = openai.responses.create(\n",
    "      model=\"gpt-5-mini\",  # ä¾‹ï¼šã‚³ã‚¹ãƒˆé‡è¦–ãªã‚‰ mini / å“è³ªé‡è¦–ãªã‚‰ gpt-5\n",
    "      input=prompt,\n",
    "      tools=[{\"type\": \"web_search\"}]  # å†…è”µWebæ¤œç´¢ã‚’æœ‰åŠ¹åŒ–\n",
    "    )\n",
    "    print(resp.output_text)\n",
    "  print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZWwGZ-C986o"
   },
   "source": [
    "## å–¶æ¥­æ–‡ç« ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BbghYR8v14iG"
   },
   "outputs": [],
   "source": [
    "# pip install openai  # æœªå°å…¥ãªã‚‰\n",
    "import os, re\n",
    "from openai import OpenAI\n",
    "\n",
    "def generate_sales_copy_with_infomation(\n",
    "    company_info: dict,\n",
    "    prompt_template: str,\n",
    "    *,\n",
    "    model: str = \"gpt-5-mini\",   # ä¾‹: GPT-5 mini ç³»ã€‚ç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´å¯\n",
    "    temperature: float = 1.0,\n",
    "    timeout: int = 120,\n",
    "    api_key: str | None = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Webæ¤œç´¢ã¯ä½¿ã‚ãšã€ä¸ãˆã‚‰ã‚ŒãŸä¼šç¤¾æƒ…å ±ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ã‹ã‚‰å–¶æ¥­æ–‡ç« ã‚’ç”Ÿæˆã™ã‚‹ã€‚\n",
    "    - company_info: {\n",
    "        \"company_name\", \"business_type\", \"other_label\", \"strengths\",\n",
    "        \"values\", \"address_text\", \"evidence\", \"confidence\"\n",
    "      }\n",
    "    - prompt_template: ä¾‹ç¤ºã®å–¶æ¥­ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆ{business_type} ç­‰ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’å«ã‚€ï¼‰\n",
    "    æˆ»ã‚Šå€¤: æ—¥æœ¬èªã®å–¶æ¥­æ–‡ç« ï¼ˆæ”¹è¡Œç¶­æŒï¼‰\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) ä¼šç¤¾æƒ…å ±ã®å‰å‡¦ç†ï¼ˆæ¬ æãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n",
    "    company_name   = (company_info.get(\"company_name\") or \"\").strip() or \"è²´ç¤¾\"\n",
    "    business_type  = (company_info.get(\"business_type\") or \"\").strip() or \"ãã®ä»–\"\n",
    "    other_label    = (company_info.get(\"other_label\") or \"\").strip()\n",
    "    strengths      = (company_info.get(\"strengths\") or \"\").strip()\n",
    "    values         = (company_info.get(\"values\") or \"\").strip()\n",
    "    address_text   = (company_info.get(\"address_text\") or \"\").strip()\n",
    "\n",
    "    # \"ãã®ä»–\" ã¯ other_labelâ†’ãªã‘ã‚Œã°æ±ç§°\n",
    "    bt_final = business_type if business_type != \"ãã®ä»–\" else (other_label or \"åº—èˆ—\")\n",
    "\n",
    "    # 2) OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ\n",
    "    client = OpenAI(api_key=api_key or os.getenv(\"OPENAI_API_KEY\", \"\"))\n",
    "\n",
    "    # 3) ä¼šè©±è¨­å®šï¼ˆæ•¬æ„å¥ã¯å®šå‹ã«ã›ãšè‡ªç„¶æ–‡ã§ï¼‰\n",
    "    system_msg = (\n",
    "        \"ã‚ãªãŸã¯æ—¥æœ¬èªã®B2Bå–¶æ¥­ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\"\n",
    "        \"å…¥åŠ›ã¨ã—ã¦ä¼šç¤¾æƒ…å ±ï¼ˆä¸€æ¬¡æƒ…å ±ç”±æ¥ã®è¦ç´„ï¼‰ã¨å–¶æ¥­ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒä¸ãˆã‚‰ã‚Œã¾ã™ã€‚\"\n",
    "        \"å–¶æ¥­ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯å®Œå…¨ã«ãƒ•ã‚©ãƒ­ãƒ¼ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚ˆã‚Šè‡ªç„¶ãªæ—¥æœ¬èªã«ã—ã¦ãã ã•ã„ã€‚\"\n",
    "        \"ãŸã ã—ã€å–¶æ¥­ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æœ€å¾Œã«ã‚ã‚‹ã€ã“ã¡ã‚‰ã®é€£çµ¡æƒ…å ±ã¯å¿…ãšæ­£ç¢ºã«éä¸è¶³ãªãåæ˜ ã•ã›ã¦ãã ã•ã„ã€‚\"\n",
    "        \"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’åŸ‹ã‚ã€æ‹¬å¼§å†…ã®æŒ‡ç¤ºéƒ¨åˆ†ã¯äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®è‡ªç„¶ãªä¸€æ–‡ã§ç½®æ›ã—ã¦ãã ã•ã„ã€‚\"\n",
    "        \"å¼•ç”¨ç•ªå·ã‚„ç”Ÿã®URLãƒªãƒ³ã‚¯ã¯æœ¬æ–‡ã«å…¥ã‚Œãªã„ã§ãã ã•ã„ï¼ˆç½²åæ¬„ã«å«ã¾ã‚Œã‚‹å›ºå®šURLã¯å¯ï¼‰ã€‚\"\n",
    "        \"æ–‡ä½“ã¯ä¸å¯§ã€èª‡å¼µã¯é¿ã‘ã€æ”¹è¡Œãƒ»æ®µè½æ§‹æˆã¯ä¿ã£ã¦ãã ã•ã„ã€‚\"\n",
    "    )\n",
    "\n",
    "    # 4) ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼šä¼šç¤¾æƒ…å ±ï¼‹ãƒ†ãƒ³ãƒ—ãƒ¬\n",
    "    user_msg = f\"\"\"\n",
    "# ä¼šç¤¾æƒ…å ±ï¼ˆä¸€æ¬¡æƒ…å ±ã®è¦ç´„ï¼‰\n",
    "company_name: {company_name}\n",
    "business_type: {bt_final}\n",
    "strengths: {strengths}\n",
    "values: {values}\n",
    "address_text: {address_text}\n",
    "\n",
    "# é‡è¦ãªãƒ«ãƒ¼ãƒ«\n",
    "- business_type ã¯ãã®ã¾ã¾ã€Œ{{business_type}}ã€ã¸å·®ã—è¾¼ã¿ï¼ˆè¨€ã„æ›ãˆä¸å¯ï¼‰ã€‚\n",
    "- ã€Œï¼ˆã“ã“ã«{{strengths}}ã‚„{{values}}ã‚ˆã‚Šã€ã“ã®äº‹æ¥­æ‰€ã‚’ç§°ãˆã‚‹æ–‡ç« ã‚’ã„ã‚Œã¦ï¼‰ã€ã®éƒ¨åˆ†ã¯ã€\n",
    "  strengths/values ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å…·ä½“ã‚’1ã€œ2ç‚¹ã ã‘ç¹”ã‚Šè¾¼ã‚“ã **è‡ªç„¶ãª1æ–‡**ã§ç½®æ›ã™ã‚‹ã“ã¨ã€‚\n",
    "- å¼•ç”¨ç•ªå·ã‚„URLãƒªãƒ³ã‚¯ã¯æœ¬æ–‡ã«å…¥ã‚Œãªã„ã€‚\n",
    "- å‡ºåŠ›ã¯æœ¬æ–‡ã®ã¿ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ç¦æ­¢ï¼‰ã€‚\n",
    "\n",
    "# å–¶æ¥­ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ\n",
    "        {\n",
    "            prompt_template\n",
    "        }\n",
    "    \"\"\".strip()\n",
    "\n",
    "    # print(\"prompt:\",\"=\"*80)\n",
    "    # print(user_msg)\n",
    "    # print(\"=\"*80)\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\":\"system\", \"content\": system_msg},\n",
    "            {\"role\":\"user\",   \"content\": user_msg},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    text = resp.choices[0].message.content.strip()\n",
    "\n",
    "    # ãƒ•ã‚§ãƒ³ã‚¹é™¤å» & ä½™è¨ˆãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å¯¾ç­–\n",
    "    text = re.sub(r\"^```(?:\\w+)?\\s*|\\s*```$\", \"\", text, flags=re.S).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\qingy\\anaconda3\\python.exe\n",
      "Python version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "Python path: ['c:\\\\Users\\\\qingy\\\\Documents\\\\è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ å–¶æ¥­äº‹æ¥­\\\\form-sales\\\\notebooks\\\\form_url_fetching_and_messege_writing', 'c:\\\\Users\\\\qingy\\\\anaconda3\\\\python312.zip', 'c:\\\\Users\\\\qingy\\\\anaconda3\\\\DLLs']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Python path:\", sys.path[:3])  # æœ€åˆã®3ã¤ã®ãƒ‘ã‚¹ã‚’è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUT2pDUh-PoX"
   },
   "source": [
    "#### ãƒ†ã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuL4XRFB6Dbf",
    "outputId": "dbfda394-5be8-4f7e-a155-1e4232a0ef7d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "urls = [\n",
    "    # \"https://www.2and4-auto.jp/\",\n",
    "    # \"https://www.cardrshuu.com/#contact\",\n",
    "    # \"http://www.nomiyama-car.com/contact/\",\n",
    "    # \"https://h-bpc.com/\",\n",
    "    # \"https://tauros-japan.com/\",\n",
    "    # \"https://www.saitomotor-hirosaki.com/\",\n",
    "    # \"https://kurumayakoubou.jp/\",\n",
    "]\n",
    "for url in urls:\n",
    "  resp = openai.responses.create(\n",
    "    model=\"gpt-5-mini\",  # ä¾‹ï¼šã‚³ã‚¹ãƒˆé‡è¦–ãªã‚‰ mini / å“è³ªé‡è¦–ãªã‚‰ gpt-5\n",
    "    input=PROMPT_CLASSIFY.format(hp_url=url,vocab_list=\", \".join(BUSINESS_TYPE_VOCAB)),\n",
    "    tools=[{\"type\": \"web_search\"}]  # å†…è”µWebæ¤œç´¢ã‚’æœ‰åŠ¹åŒ–\n",
    "  )\n",
    "  comp_data = json.loads(resp.output_text)\n",
    "  text = generate_sales_copy_with_infomation(comp_data, PROMPT, model=\"gpt-5-mini\")\n",
    "  print(text)\n",
    "  # print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzGD3GSP6DJM"
   },
   "source": [
    "# å®Ÿè¡Œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dfã®æ ¼ç´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, re\n",
    "import pandas as pd\n",
    "\n",
    "# Detect form-sales root on both VM and local\n",
    "\n",
    "def get_form_sales_root() -> Path:\n",
    "    env = os.getenv(\"FORM_SALES_ROOT\")\n",
    "    if env:\n",
    "        p = Path(env)\n",
    "        if p.exists():\n",
    "            return p\n",
    "    # Prefer module location to avoid CWD-induced duplicates like 'form-sales/form-sales'\n",
    "    try:\n",
    "        this_file = Path(__file__).resolve()\n",
    "        # .../form-sales/src/form_url_fetch_msg_write_py/_01_helpers.py â†’ root = parents[2]\n",
    "        module_root = this_file.parents[2]\n",
    "        if (module_root / \"src\").exists():\n",
    "            return module_root\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: Walk up to find a directory that looks like the project root\n",
    "    cwd = Path.cwd()\n",
    "    for p in [cwd, *cwd.parents]:\n",
    "        # 1) If this dir itself is named 'form-sales' and has 'src', use it\n",
    "        if p.name == \"form-sales\" and (p / \"src\").exists():\n",
    "            return p\n",
    "        # 2) If a child named 'form-sales' exists and has 'src', use it\n",
    "        child = p / \"form-sales\"\n",
    "        if child.exists() and child.is_dir() and (child / \"src\").exists():\n",
    "            return child\n",
    "    return cwd\n",
    "\n",
    "def resolve_incoming_dir() -> Path:\n",
    "    \"\"\"Resolve incoming directory each call to avoid stale env values and ensure it exists.\"\"\"\n",
    "    env_dir = os.getenv(\"INCOMING_DIR\")\n",
    "    base = Path(env_dir) if env_dir else (get_form_sales_root() / \"data\" / \"targets\" / \"incoming\")\n",
    "    # Normalize and ensure existence\n",
    "    base = base.resolve()\n",
    "    try:\n",
    "        base.mkdir(parents=True, exist_ok=True)\n",
    "    except Exception:\n",
    "        # If creation fails (e.g., permission), continue; caller will error clearly\n",
    "        pass\n",
    "    return base\n",
    "\n",
    "CLIENT_FILE_REGEX = re.compile(r\"^(?P<client_id>[A-Za-z0-9_-]+)_\\d{8}\\.csv$\", re.IGNORECASE)\n",
    "\n",
    "def find_latest_incoming_csv(directory: Path) -> tuple[str, Path]:\n",
    "    \"\"\"\n",
    "    Find the latest CSV matching pattern '<clientid>_YYYYMMDD.csv' in the given directory.\n",
    "    Returns (client_id, file_path).\n",
    "    \"\"\"\n",
    "    if not directory.exists():\n",
    "        raise FileNotFoundError(f\"Incoming directory not found: {directory}\")\n",
    "    candidates: list[tuple[str, Path]] = []\n",
    "    for p in directory.glob(\"*.csv\"):\n",
    "        m = CLIENT_FILE_REGEX.match(p.name)\n",
    "        if m:\n",
    "            candidates.append((m.group(\"client_id\"), p))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No CSV like '<clientid>_YYYYMMDD.csv' in: {directory}\")\n",
    "    # latest by modified time\n",
    "    candidates.sort(key=lambda t: t[1].stat().st_mtime, reverse=True)\n",
    "    return candidates[0]\n",
    "\n",
    "def load_incoming_df() -> tuple[str, pd.DataFrame, Path]:\n",
    "    \"\"\"\n",
    "    Resolve the incoming CSV path in a VM-friendly way and return (client_id, df, path).\n",
    "    Priority:\n",
    "      1) ENV INCOMING_DIR if provided\n",
    "      2) auto-detected 'form-sales/data/targets/incoming'\n",
    "    \"\"\"\n",
    "    incoming_dir = resolve_incoming_dir()\n",
    "    client_id, p = find_latest_incoming_csv(incoming_dir)\n",
    "    # read with UTF-8 BOM tolerant\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {p}\")\n",
    "    ext = p.suffix.lower()\n",
    "    df = pd.read_excel(p) if ext in {\".xlsx\", \".xls\"} else pd.read_csv(p, encoding=\"utf-8-sig\")\n",
    "    return client_id, df, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å–¶æ¥­æ–‡ç« ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Optional, Iterable\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "# äº‹å‰: !pip -q install tqdm openai\n",
    "\n",
    "def _extract_json(text: str) -> str:\n",
    "    s = text.strip()\n",
    "    s = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", s, flags=re.S).strip()\n",
    "    m = re.search(r\"\\{[\\s\\S]*\\}$\", s)\n",
    "    return (m.group(0) if m else s)\n",
    "\n",
    "\n",
    "def fill_sales_copy_with_gpt(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    url_col: str = \"hp_url\",\n",
    "    out_col: str = \"sales_copy\",\n",
    "    model: str = \"gpt-5-mini\",\n",
    "    classify_prompt_template: str = None,   # ä¾‹: PROMPT_CLASSIFY\n",
    "    sales_prompt_template: str = None,      # ä¾‹: PROMPT\n",
    "    business_vocab: Optional[Iterable[str]] = None,  # ä¾‹: BUSINESS_TYPE_VOCAB\n",
    "    overwrite: bool = True,\n",
    "    sleep_sec: float = 0.8,\n",
    "    openai_api_key: Optional[str] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    å„è¡Œ: hp_url -> (åˆ†é¡JSON) -> generate_sales_copy_with_infomation -> sales_copy ã«æ ¼ç´\n",
    "    é€²æ—ãƒãƒ¼ã¯1æœ¬ã ã‘è¡¨ç¤ºã€‚å–¶æ¥­æ–‡ç”Ÿæˆæ™‚ã« \"record_created_at\" ã‚’ \"YYYY-MM-DD HH:MM:SS\" ã§è¨˜éŒ²ã€‚\n",
    "    \"\"\"\n",
    "    # å‡ºåŠ›åˆ—ã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ã®ç”¨æ„\n",
    "    if out_col not in df.columns:\n",
    "        df.loc[:, out_col] = \"\"\n",
    "    record_col = \"record_created_at\"\n",
    "    if record_col not in df.columns:\n",
    "        df.loc[:, record_col] = pd.NaT\n",
    "\n",
    "    if (\n",
    "        classify_prompt_template is None\n",
    "        or sales_prompt_template is None\n",
    "        or business_vocab is None\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"classify_prompt_template / sales_prompt_template / business_vocab ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\"\n",
    "        )\n",
    "\n",
    "    client = OpenAI(api_key=openai_api_key or os.getenv(\"OPENAI_API_KEY\", \"\"))\n",
    "    mask = df[url_col].notna() & df[url_col].astype(str).str.strip().ne(\"\")\n",
    "    idxs = df[mask].index\n",
    "    vocab_str = \", \".join(business_vocab)\n",
    "\n",
    "    # --- é€²æ—ãƒãƒ¼ ---\n",
    "    for i in tqdm(idxs, total=len(idxs), desc=\"å–¶æ¥­æ–‡ç”Ÿæˆ\", unit=\"ç¤¾\"):\n",
    "        # æ—¢å­˜ã®å‡ºåŠ›ãŒã‚ã‚Šã€ã‹ã¤ä¸Šæ›¸ãã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "        if (not overwrite) and isinstance(df.at[i, out_col], str) and df.at[i, out_col].strip():\n",
    "            continue\n",
    "\n",
    "        url = str(df.at[i, url_col]).strip()\n",
    "        try:\n",
    "            # 1) åˆ†é¡ï¼ˆJSONç”Ÿæˆãƒ»Webæ¤œç´¢ONï¼‰\n",
    "            prompt_cls = classify_prompt_template.format(hp_url=url, vocab_list=vocab_str)\n",
    "            resp = client.responses.create(\n",
    "                model=model,\n",
    "                input=prompt_cls,\n",
    "                tools=[{\"type\": \"web_search\"}],\n",
    "            )\n",
    "            comp_json = _extract_json(resp.output_text)\n",
    "            comp_data = json.loads(comp_json)\n",
    "\n",
    "            # 2) å–¶æ¥­æ–‡ç”Ÿæˆï¼ˆæ¤œç´¢ãªã—ï¼‰\n",
    "            text = generate_sales_copy_with_infomation(\n",
    "                company_info=comp_data,\n",
    "                prompt_template=sales_prompt_template,\n",
    "                model=model,\n",
    "                temperature=1.0,\n",
    "            )\n",
    "            text_str = (text or \"\").strip()\n",
    "            df.at[i, out_col] = text_str\n",
    "\n",
    "            # ç”Ÿæˆã§ããŸå ´åˆã®ã¿ä½œæˆæ—¥æ™‚ã‚’è¨˜éŒ²ï¼ˆãƒ‡ãƒ¼ãƒˆå‹: ç§’ç²¾åº¦ï¼‰\n",
    "            if text_str:\n",
    "                df.at[i, record_col] = pd.Timestamp.now().floor(\"S\")\n",
    "\n",
    "        except Exception:\n",
    "            # å¤±æ•—æ™‚ã¯å‡ºåŠ›ã‚’ç©ºã«ã—ã€ä½œæˆæ—¥æ™‚ã¯æ›´æ–°ã—ãªã„\n",
    "            df.at[i, out_col] = \"\"\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big queryæ›¸ãè¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\qingy\\anaconda3\\lib\\site-packages (3.36.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage in c:\\users\\qingy\\anaconda3\\lib\\site-packages (2.32.0)\n",
      "Requirement already satisfied: pandas-gbq in c:\\users\\qingy\\anaconda3\\lib\\site-packages (0.29.2)\n",
      "Requirement already satisfied: db-dtypes in c:\\users\\qingy\\anaconda3\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\qingy\\anaconda3\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.40.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=24.2.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (25.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.32.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery-storage) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-cloud-bigquery-storage) (6.32.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pandas-gbq) (75.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pandas-gbq) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pandas-gbq) (2.2.2)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pandas-gbq) (1.9.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pandas-gbq) (1.2.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq) (2.0.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->pandas-gbq) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->pandas-gbq) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\qingy\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq) (3.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U google-cloud-bigquery google-cloud-bigquery-storage pandas-gbq db-dtypes pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde501a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google.auth\n",
    "# creds, adc_proj = google.auth.default()\n",
    "# from google.cloud import bigquery\n",
    "# client = bigquery.Client()\n",
    "# print(\"ADC:\", adc_proj, \"Client:\", client.project)  # ä¸¡æ–¹ãŒ 469308 å´ã«ãªã£ã¦ã„ã‚Œã°OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BigQuery: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ/ãƒ†ãƒ¼ãƒ–ãƒ«è¨­å®šã¨ã‚¹ã‚­ãƒ¼ãƒç¢ºèª (â‘ ã‚«ãƒ©ãƒ ã‚’æ´—ã„å‡ºã™)\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # 469308 å´ã‚’æ—¢å®šã«ã€‚å¿…è¦ãªã‚‰æ›¸ãæ›ãˆå¯\n",
    "# GCLOUD_PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\") or os.getenv(\"GCLOUD_PROJECT\") or \"test-250817-469308\"\n",
    "# DATASET_ID = \"dev\"           # ã“ã“ã‚’å®Ÿç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´å¯\n",
    "# TABLE_ID = \"sales_list\"      # ã“ã“ã‚’å®Ÿç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´å¯\n",
    "# TABLE_FQN = f\"{GCLOUD_PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
    "\n",
    "# client = bigquery.Client(project=GCLOUD_PROJECT_ID, location=\"asia-northeast1\")\n",
    "\n",
    "# # ã‚¹ã‚­ãƒ¼ãƒå–å¾—\n",
    "# _table = client.get_table(TABLE_FQN)\n",
    "# schema_df = pd.DataFrame([\n",
    "#     {\"name\": f.name, \"type\": f.field_type, \"mode\": f.mode, \"description\": f.description}\n",
    "#     for f in _table.schema\n",
    "# ])\n",
    "# print(\"TABLE:\", TABLE_FQN)\n",
    "# print(schema_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import bigquery\n",
    "# import pandas as pd\n",
    "\n",
    "# # æ—¢å­˜ã® PROJECT_ID/DATASET_ID/TABLE_ID/TABLE_FQN ã¯ä¸Šã®ã‚»ãƒ«ã®å€¤ã‚’æµç”¨\n",
    "# sent_at_value = \"2020-01-01 00:00:00\"  # DATETIMEç”¨ï¼ˆã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãªã—ï¼‰\n",
    "\n",
    "# data = [\n",
    "#     {\n",
    "#         \"client_id\": \"TEST-001\",\n",
    "#         \"recipient_company_name\": \"æ ªå¼ä¼šç¤¾ãƒ†ã‚¹ãƒˆ1\",\n",
    "#         \"hp_url\": \"https://example.com/1\",\n",
    "#         \"contact_url\": \"https://example.com/1/contact\",\n",
    "#         \"sales_copy\": \"ã”æŒ¨æ‹¶1\",\n",
    "#         \"record_created_at\": sent_at_value,\n",
    "#         \"sent_at\": sent_at_value,\n",
    "#         \"send_status\": \"draft\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"client_id\": \"TEST-002\",\n",
    "#         \"recipient_company_name\": \"æ ªå¼ä¼šç¤¾ãƒ†ã‚¹ãƒˆ2\",\n",
    "#         \"hp_url\": \"https://example.com/2\",\n",
    "#         \"contact_url\": \"https://example.com/2/contact\",\n",
    "#         \"sales_copy\": \"ã”æŒ¨æ‹¶2\",\n",
    "#         \"record_created_at\": sent_at_value,\n",
    "#         \"sent_at\": sent_at_value,\n",
    "#         \"send_status\": \"draft\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"client_id\": \"TEST-003\",\n",
    "#         \"recipient_company_name\": \"æ ªå¼ä¼šç¤¾ãƒ†ã‚¹ãƒˆ3\",\n",
    "#         \"hp_url\": \"https://example.com/3\",\n",
    "#         \"contact_url\": \"https://example.com/3/contact\",\n",
    "#         \"sales_copy\": \"ã”æŒ¨æ‹¶3\",\n",
    "#         \"record_created_at\": sent_at_value,\n",
    "#         \"sent_at\": sent_at_value,\n",
    "#         \"send_status\": \"draft\",\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# insert_df = df[[c for c in df.columns if c in schema_df[\"name\"].tolist()]].copy()\n",
    "\n",
    "# # å¿µã®ãŸã‚ DATETIME ã¨ã—ã¦è§£é‡ˆã•ã›ã‚‹ï¼ˆtz ãªã—ï¼naiveï¼‰\n",
    "# insert_df[\"sent_at\"] = pd.to_datetime(insert_df[\"sent_at\"]).dt.tz_localize(None)\n",
    "# insert_df[\"record_created_at\"] = pd.to_datetime(insert_df[\"record_created_at\"]).dt.tz_localize(None)\n",
    "\n",
    "# client = bigquery.Client(project=GCLOUD_PROJECT_ID, location=\"asia-northeast1\")\n",
    "# job = client.load_table_from_dataframe(\n",
    "#     insert_df,\n",
    "#     TABLE_FQN,\n",
    "#     bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
    "# )\n",
    "# job.result()\n",
    "# print(\"loaded rows:\", len(insert_df))\n",
    "\n",
    "# # æ¤œè¨¼ï¼ˆä»Šå…¥ã‚ŒãŸ client_id ã ã‘å–å¾—ï¼‰\n",
    "# keys = insert_df[\"client_id\"].tolist()\n",
    "# qry = f\"\"\"\n",
    "# SELECT client_id, recipient_company_name, hp_url, contact_url, sales_copy, sent_at, record_created_at, send_status\n",
    "# FROM `{TABLE_FQN}`\n",
    "# WHERE client_id IN UNNEST(@keys)\n",
    "# ORDER BY client_id\n",
    "# \"\"\"\n",
    "# res = client.query(\n",
    "#     qry,\n",
    "#     job_config=bigquery.QueryJobConfig(\n",
    "#         query_parameters=[bigquery.ArrayQueryParameter(\"keys\", \"STRING\", keys)]\n",
    "#     ),\n",
    "# ).result().to_dataframe()\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_contact_url_filled_df_for_bq(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    client_id: Optional[str] = None,\n",
    "    send_status_value: str = \"æœªé€ä¿¡\",\n",
    "    sent_at_value: str = \"2020-01-01 00:00:00\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    contact_url_filled_dfï¼ˆå–¶æ¥­æ–‡ç”Ÿæˆå¾Œã®DFï¼‰ã‚’ BigQueryæŠ•å…¥ç”¨ã«æ•´å½¢ã™ã‚‹ã€‚\n",
    "\n",
    "    å®Ÿæ–½å†…å®¹:\n",
    "      - åˆ—åå¤‰æ›´: \"company_name\" â†’ \"recipient_company_name\"\n",
    "      - åˆ—è¿½åŠ :  \"client_id\"ï¼ˆæŒ‡å®šãŒã‚ã‚Œã°å…¨è¡Œã«è¨­å®šã€æœªæŒ‡å®šæ™‚ã¯ç©ºæ–‡å­—ï¼‰\n",
    "      - åˆ—è¿½åŠ :  \"send_status\"ï¼ˆå…¨è¡Œ \"æœªé€ä¿¡\"ï¼‰\n",
    "      - åˆ—è¿½åŠ :  \"sent_at\"ï¼ˆå…¨è¡Œ \"2020-01-01 00:00:00\"ï¼‰\n",
    "\n",
    "    æ—¢å­˜åˆ—ãŒã‚ã‚‹å ´åˆã‚‚ã€\"send_status\" ã¨ \"sent_at\" ã¯æŒ‡å®šã®å®šæ•°ã§ä¸Šæ›¸ãã™ã‚‹ã€‚\n",
    "    å…ƒã® DataFrame ã¯å¤‰æ›´ã›ãšã€åŠ å·¥å¾Œã®ã‚³ãƒ”ãƒ¼ã‚’è¿”ã™ã€‚\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # 1) åˆ—åå¤‰æ›´ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰\n",
    "    if \"company_name\" in out.columns and \"recipient_company_name\" not in out.columns:\n",
    "        out = out.rename(columns={\"company_name\": \"recipient_company_name\"})\n",
    "\n",
    "    # 2) client_id åˆ—ã®ç”¨æ„ã¨è¨­å®š\n",
    "    if \"client_id\" not in out.columns:\n",
    "        out.loc[:, \"client_id\"] = \"\"\n",
    "    if client_id is not None:\n",
    "        out.loc[:, \"client_id\"] = str(client_id)\n",
    "\n",
    "    # 3) send_status / sent_at ã‚’å®šæ•°ã§ä»˜ä¸ï¼ˆä¸Šæ›¸ãï¼‰\n",
    "    out.loc[:, \"send_status\"] = send_status_value\n",
    "    out.loc[:, \"sent_at\"] = sent_at_value\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a6d5d",
   "metadata": {},
   "source": [
    "## BQã¸æ ¼ç´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "# from __future__ import annotations\n",
    "\n",
    "from typing import Iterable, Mapping, Optional\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "\n",
    "def load_sales_list_df_to_bq(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    project_id: str,\n",
    "    dataset_id: str = \"dev\",\n",
    "    table_id: str = \"sales_list\",\n",
    "    location: str = \"asia-northeast1\",\n",
    "    write_disposition: str = \"WRITE_APPEND\",\n",
    "    require_all_columns: bool = True,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Load a DataFrame to BigQuery table `{project_id}.{dataset_id}.{table_id}` with\n",
    "    schema alignment for the following columns:\n",
    "      - client_id (STRING, REQUIRED)\n",
    "      - recipient_company_name (STRING, REQUIRED)\n",
    "      - hp_url (STRING, REQUIRED)\n",
    "      - contact_url (STRING, REQUIRED)\n",
    "      - sales_copy (STRING, REQUIRED)\n",
    "      - record_created_at (DATETIME, REQUIRED)\n",
    "      - sent_at (DATETIME, REQUIRED)\n",
    "      - send_status (STRING, REQUIRED)\n",
    "\n",
    "    Notes on authentication for VM:\n",
    "    - If this runs on a GCE/Cloud Run/Composer VM with an attached service account,\n",
    "      the BigQuery client will automatically use Application Default Credentials (ADC).\n",
    "      No human login is required if the service account has `roles/bigquery.dataEditor`\n",
    "      (or appropriate) on the target dataset/table.\n",
    "    - Locally, you can also set GOOGLE_APPLICATION_CREDENTIALS to a service account JSON.\n",
    "\n",
    "    Returns: number of rows loaded.\n",
    "    \"\"\"\n",
    "    required_columns = [\n",
    "        \"client_id\",\n",
    "        \"recipient_company_name\",\n",
    "        \"hp_url\",\n",
    "        \"contact_url\",\n",
    "        \"sales_copy\",\n",
    "        \"record_created_at\",\n",
    "        \"sent_at\",\n",
    "        \"send_status\",\n",
    "    ]\n",
    "\n",
    "    # 1) å¿…é ˆåˆ—ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯\n",
    "    missing = [c for c in required_columns if c not in df.columns]\n",
    "    if missing and require_all_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # 2) ã‚¹ã‚­ãƒ¼ãƒé †ã«ãã‚ãˆãŸã‚³ãƒ”ãƒ¼ã‚’ä½œæˆï¼ˆä½™åˆ†åˆ—ã¯è½ã¨ã™ï¼‰\n",
    "    use_cols = [c for c in required_columns if c in df.columns]\n",
    "    insert_df = df[use_cols].copy()\n",
    "\n",
    "    # 3) å‹ã®æ­£è¦åŒ–\n",
    "    string_cols = [\n",
    "        \"client_id\",\n",
    "        \"recipient_company_name\",\n",
    "        \"hp_url\",\n",
    "        \"contact_url\",\n",
    "        \"sales_copy\",\n",
    "        \"send_status\",\n",
    "    ]\n",
    "    for col in string_cols:\n",
    "        if col in insert_df:\n",
    "            insert_df[col] = insert_df[col].astype(\"string\").fillna(\"\")\n",
    "\n",
    "    # DATETIMEï¼ˆtz ãªã—ï¼‰ã¸å¤‰æ›ã€‚None/ç©ºæ–‡å­—/\"None\" ã¯ NaT ã«ãªã‚‹ã®ã§äº‹å‰ã«å¼¾ããªã‚‰ã“ã“ã§å¯¾å¿œ\n",
    "    for col in [\"record_created_at\", \"sent_at\"]:\n",
    "        if col in insert_df:\n",
    "            series = (\n",
    "                insert_df[col]\n",
    "                .replace({\"None\": None})\n",
    "                .astype(\"string\")\n",
    "                .where(lambda s: s.str.strip().ne(\"\"), None)\n",
    "            )\n",
    "            insert_df[col] = pd.to_datetime(series, errors=\"coerce\")\n",
    "            # BigQuery DATETIME ã¯ tz ãªã—ã€NaT ã¯è¨±å®¹ã—ãªã„ã®ã§æœ€çµ‚ãƒã‚§ãƒƒã‚¯\n",
    "            if insert_df[col].isna().any():\n",
    "                bad_idx = insert_df[col][insert_df[col].isna()].index.tolist()\n",
    "                raise ValueError(f\"Invalid DATETIME in column '{col}' at rows: {bad_idx[:10]} ...\")\n",
    "\n",
    "    table_fqn = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "    client = bigquery.Client(project=project_id, location=location)\n",
    "    job = client.load_table_from_dataframe(\n",
    "        insert_df,\n",
    "        table_fqn,\n",
    "        job_config=bigquery.LoadJobConfig(write_disposition=write_disposition),\n",
    "    )\n",
    "    job.result()\n",
    "    return len(insert_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "20d9209b5bed43a4989322b110abca7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4e439a8899642198f22667d43945673",
       "IPY_MODEL_7d93eb22d9ca491aa1614d56ba06e1b6",
       "IPY_MODEL_48ec91f9210f4a18bc37a8a29d4cf4c3"
      ],
      "layout": "IPY_MODEL_c0fe43163321447d8d74fbbe5c99d973"
     }
    },
    "21f94c8a7fbd477c8165f794582a2e8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3071f4f900f44f3583a681f18a565968": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48ec91f9210f4a18bc37a8a29d4cf4c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af65e194f67b49078c869f190c0de178",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_21f94c8a7fbd477c8165f794582a2e8d",
      "value": "â€‡7/7â€‡[04:07&lt;00:00,â€‡37.25s/ç¤¾]"
     }
    },
    "4c55f83e7be64a4b8588a22018204413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72cd4ad0c91f48f8a5b960e64cdf6b30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d93eb22d9ca491aa1614d56ba06e1b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72cd4ad0c91f48f8a5b960e64cdf6b30",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c55f83e7be64a4b8588a22018204413",
      "value": 7
     }
    },
    "a4e439a8899642198f22667d43945673": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3071f4f900f44f3583a681f18a565968",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fbe16c8aa373435faaee0ba5d6f5ac6a",
      "value": "å–¶æ¥­æ–‡ç”Ÿæˆ:â€‡100%"
     }
    },
    "af65e194f67b49078c869f190c0de178": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0fe43163321447d8d74fbbe5c99d973": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbe16c8aa373435faaee0ba5d6f5ac6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
